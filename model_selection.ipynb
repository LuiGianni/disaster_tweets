{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing datasets\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15                  What's up man?\n",
       "16                   I love fruits\n",
       "17                Summer is lovely\n",
       "18               My car is so fast\n",
       "19    What a goooooooaaaaaal!!!!!!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the training dataset\n",
    "train_df[train_df[\"target\"] == 0][\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset is targeted, 0 or 1, where 0 means 'not a disaster tweet', so we can use it to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   000  13  alaska  allah  asked  california  canada  deeds  earthquake  \\\n",
      "0    0   0       0      1      0           0       0      1           1   \n",
      "1    0   0       0      0      0           0       1      0           0   \n",
      "2    0   0       0      0      1           0       0      0           0   \n",
      "3    1   1       0      0      0           1       0      0           0   \n",
      "4    0   0       1      0      0           0       0      0           0   \n",
      "\n",
      "   evacuation  ...  receive  residents  ronge  ruby  sask  school  sent  \\\n",
      "0           0  ...        0          0      0     0     0       0     0   \n",
      "1           0  ...        0          0      1     0     1       0     0   \n",
      "2           1  ...        0          1      0     0     0       0     0   \n",
      "3           1  ...        1          0      0     0     0       0     0   \n",
      "4           0  ...        0          0      0     1     0       1     1   \n",
      "\n",
      "   shelter  smoke  wildfires  \n",
      "0        0      0          0  \n",
      "1        0      0          0  \n",
      "2        2      0          0  \n",
      "3        0      0          1  \n",
      "4        0      1          1  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "(5, 35)\n",
      "[[0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 2 0 0 0 1 0 0 0 0 0 2 0 0]\n",
      " [1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# let's get counts for the first 5 tweets in the data\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer(stop_words=\"english\", min_df=1)\n",
    "\n",
    "## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])\n",
    "example_df = pd.DataFrame(data=example_train_vectors.todense(),columns = count_vectorizer.get_feature_names_out())\n",
    "print(example_df)\n",
    "print(example_train_vectors.shape)\n",
    "print(example_train_vectors.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 1647)\n",
      "      00  01  04  05  06  07  08  10  100  11  ...  zone  û_  ûª  ûªs  ûªt  \\\n",
      "0      0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "1      0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "2      0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "3      0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "4      0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ...   ...  ..  ..  ...  ...   \n",
      "7608   0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "7609   0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "7610   0   1   1   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "7611   0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "7612   0   0   0   0   0   0   0   0    0   0  ...     0   0   0    0    0   \n",
      "\n",
      "      ûªve  ûï  ûïwhen  ûò  ûó  \n",
      "0        0   0       0   0   0  \n",
      "1        0   0       0   0   0  \n",
      "2        0   0       0   0   0  \n",
      "3        0   0       0   0   0  \n",
      "4        0   0       0   0   0  \n",
      "...    ...  ..     ...  ..  ..  \n",
      "7608     0   0       0   0   0  \n",
      "7609     0   0       0   0   0  \n",
      "7610     0   0       0   0   0  \n",
      "7611     0   0       0   0   0  \n",
      "7612     0   0       0   0   0  \n",
      "\n",
      "[7613 rows x 1647 columns]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer( min_df=0.001, stop_words=\"english\")\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
    "# i.e. that the train and test vectors use the same set of tokens.\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "df = pd.DataFrame(data=train_vectors.todense(),columns = count_vectorizer.get_feature_names_out())\n",
    "print(train_vectors.shape)\n",
    "print(df)\n",
    "print(train_vectors.todense())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model\n",
    "\n",
    "As we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n",
    "\n",
    "What we're assuming here is a linear connection. So let's build a linear model and see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our vectors are really big, so we want to push our model's weights\n",
    "## toward 0 without completely discounting different words - ridge regression \n",
    "## is a good way to do this.\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48275862, 0.44736842, 0.48518519, 0.54255319, 0.43911439,\n",
       "       0.49285714, 0.52075472, 0.43220339, 0.65232975, 0.7299509 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=10, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the models we want to use\n",
    "# We use the same random state for each model to be able to compare them\n",
    "# We use the class_weight parameter to balance the classes\n",
    "# We use the max_iter parameter to avoid convergence warnings\n",
    "# We use the n_estimators parameter to avoid convergence warnings\n",
    "# We use the max_depth parameter to avoid convergence warnings\n",
    "# We use the l1_ratio parameter to avoid convergence warnings\n",
    "# We use the eval_metric to logloss for classification\n",
    "\n",
    "# Download the libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Linear regression, k nearest neighbors, random forest, xgboost, lightgbm, naive bayes, support vector machine\n",
    "model_LR = skl.linear_model.LogisticRegression(C=0.05, l1_ratio=None, max_iter=10000)\n",
    "model_KNN = skl.neighbors.KNeighborsClassifier()\n",
    "model_RF = skl.ensemble.RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "model_XGB = XGBClassifier(n_estimators=100, max_depth=2, use_label_encoder=False, eval_metric='logloss')\n",
    "model_LGBM = LGBMClassifier(n_estimators=100, max_depth=2)\n",
    "model_SVM = svm.SVC()\n",
    "model_NBC = skl.naive_bayes.GaussianNB()\n",
    "\n",
    "# put all those models in a list\n",
    "models = [model_NBC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the libraries for the cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# define a function to perform cross validation for the given models\n",
    "def cross_validation(model, the_df, the_target, n_splits=10, random_state=71, stratified=True, shuffle=True):\n",
    "    \"\"\"\n",
    "    This function performs cross validation for the given models\n",
    "    input:\n",
    "        models: the models to be evaluated\n",
    "        X: the features\n",
    "        y: the target\n",
    "        n_splits: the number of splits\n",
    "        random_state: the random state\n",
    "    output:\n",
    "        a dataframe with the results\n",
    "    \"\"\"\n",
    "    # create a dataframe to store the results\n",
    "    results = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "    # Create conditional statement to check if stratified or not\n",
    "    if stratified:\n",
    "        # create a stratified k-fold object\n",
    "        if shuffle:\n",
    "            kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        else:\n",
    "            kf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "    else:\n",
    "        # create a non stratified k-fold object\n",
    "        if shuffle:\n",
    "            kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        else:\n",
    "            kf = KFold(n_splits=n_splits, shuffle=False) \n",
    "    # Define target and features\n",
    "    X = the_df\n",
    "    y = the_target\n",
    "    # loop over the folds\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        # split the data\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # loop over the models\n",
    "        for model in models:\n",
    "            # fit the model\n",
    "            time_0 = datetime.datetime.now()\n",
    "            model.fit(X_train, np.ravel(y_train))\n",
    "            time_1 = datetime.datetime.now()\n",
    "            # predict the target\n",
    "            y_pred = model.predict(X_test)\n",
    "            # compute the accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # compute the precision\n",
    "            precision = classification_report(y_test, y_pred, output_dict=True)['1']['precision']\n",
    "            # compute the recall\n",
    "            recall = classification_report(y_test, y_pred, output_dict=True)['1']['recall']\n",
    "            # compute the f1 score\n",
    "            f1 = classification_report(y_test, y_pred, output_dict=True)['1']['f1-score']\n",
    "            # compute the time to fit the model in seconds\n",
    "            time_fit = (time_1 - time_0).total_seconds()\n",
    "\n",
    "            # store the results in the dataframe sorted by accuracy\n",
    "            results = results.append({'model': model.__class__.__name__,\n",
    "                                      'accuracy': accuracy,\n",
    "                                      'precision': precision,\n",
    "                                      'recall': recall,\n",
    "                                      'f1': f1,\n",
    "                                      'Time to fit': time_fit}, ignore_index=True)\n",
    "\n",
    "            # group the results by model\n",
    "            results = results.groupby('model').mean().reset_index().sort_values(by='f1',\n",
    "                             ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # return the dataframe\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 21363)\n",
      "      00  000  0000  007npen6lg  00cy9vxeff  00end  00pm  01  02  0215  ...  \\\n",
      "0      0    0     0           0           0      0     0   0   0     0  ...   \n",
      "1      0    0     0           0           0      0     0   0   0     0  ...   \n",
      "2      0    0     0           0           0      0     0   0   0     0  ...   \n",
      "3      0    1     0           0           0      0     0   0   0     0  ...   \n",
      "4      0    0     0           0           0      0     0   0   0     0  ...   \n",
      "...   ..  ...   ...         ...         ...    ...   ...  ..  ..   ...  ...   \n",
      "7608   0    0     0           0           0      0     0   0   0     0  ...   \n",
      "7609   0    0     0           0           0      0     0   0   0     0  ...   \n",
      "7610   0    0     0           0           0      0     0   1   0     0  ...   \n",
      "7611   0    0     0           0           0      0     0   0   0     0  ...   \n",
      "7612   0    0     0           0           0      0     0   0   0     0  ...   \n",
      "\n",
      "      ûò  ûò800000  ûòthe  ûòåêcnbc  ûó  ûóher  ûókody  ûónegligence  ûótech  \\\n",
      "0      0         0      0         0   0      0       0             0       0   \n",
      "1      0         0      0         0   0      0       0             0       0   \n",
      "2      0         0      0         0   0      0       0             0       0   \n",
      "3      0         0      0         0   0      0       0             0       0   \n",
      "4      0         0      0         0   0      0       0             0       0   \n",
      "...   ..       ...    ...       ...  ..    ...     ...           ...     ...   \n",
      "7608   0         0      0         0   0      0       0             0       0   \n",
      "7609   0         0      0         0   0      0       0             0       0   \n",
      "7610   0         0      0         0   0      0       0             0       0   \n",
      "7611   0         0      0         0   0      0       0             0       0   \n",
      "7612   0         0      0         0   0      0       0             0       0   \n",
      "\n",
      "      ûówe  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "...    ...  \n",
      "7608     0  \n",
      "7609     0  \n",
      "7610     0  \n",
      "7611     0  \n",
      "7612     0  \n",
      "\n",
      "[7613 rows x 21363 columns]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer( min_df=1, stop_words=\"english\")\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
    "# i.e. that the train and test vectors use the same set of tokens.\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "df = pd.DataFrame(data=train_vectors.todense(),columns = count_vectorizer.get_feature_names_out())\n",
    "print(train_vectors.shape)\n",
    "print(df)\n",
    "print(train_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cross validation for the models in the for combinatotions of stratified and shuffle and retarn a 2x2 matrix of results\n",
    "# stratified = True, shuffle = True\n",
    "results_stratified_shuffle = cross_validation(models, df, train_df[\"target\"], n_splits=10, random_state=71, stratified=True, shuffle=True)\n",
    "# stratified = True, shuffle = False\n",
    "#results_stratified_noshuffle = cross_validation(models, df, train_df[\"target\"], n_splits=10, random_state=71, stratified=True, shuffle=False)\n",
    "# stratified = False, shuffle = True\n",
    "#results_nostatified_shuffle = cross_validation(models, df, train_df[\"target\"], n_splits=10, random_state=71, stratified=False, shuffle=True)\n",
    "# stratified = False, shuffle = False\n",
    "#results_nostatified_noshuffle = cross_validation(models, df, train_df[\"target\"], n_splits=10, random_state=71, stratified=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Time to fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.61713</td>\n",
       "      <td>0.536519</td>\n",
       "      <td>0.801804</td>\n",
       "      <td>0.642702</td>\n",
       "      <td>9.864703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  precision    recall        f1  Time to fit\n",
       "0  GaussianNB   0.61713   0.536519  0.801804  0.642702     9.864703"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stratified_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Time to fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.784437</td>\n",
       "      <td>0.819804</td>\n",
       "      <td>0.629208</td>\n",
       "      <td>0.710996</td>\n",
       "      <td>10.024921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.759285</td>\n",
       "      <td>0.793609</td>\n",
       "      <td>0.581180</td>\n",
       "      <td>0.670529</td>\n",
       "      <td>124.094220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.726334</td>\n",
       "      <td>0.782981</td>\n",
       "      <td>0.487209</td>\n",
       "      <td>0.600211</td>\n",
       "      <td>7.488531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.857808</td>\n",
       "      <td>0.343001</td>\n",
       "      <td>0.488294</td>\n",
       "      <td>0.373013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.578071</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>4.343087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy  precision    recall        f1  \\\n",
       "0      LogisticRegression  0.784437   0.819804  0.629208  0.710996   \n",
       "1           XGBClassifier  0.759285   0.793609  0.581180  0.670529   \n",
       "2          LGBMClassifier  0.726334   0.782981  0.487209  0.600211   \n",
       "3    KNeighborsClassifier  0.697505   0.857808  0.343001  0.488294   \n",
       "4  RandomForestClassifier  0.578071   0.257812  0.001601  0.003183   \n",
       "\n",
       "   Time to fit  \n",
       "0    10.024921  \n",
       "1   124.094220  \n",
       "2     7.488531  \n",
       "3     0.373013  \n",
       "4     4.343087  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nostatified_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Time to fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.752025</td>\n",
       "      <td>0.747722</td>\n",
       "      <td>0.637343</td>\n",
       "      <td>0.684628</td>\n",
       "      <td>11.997390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.710646</td>\n",
       "      <td>0.720827</td>\n",
       "      <td>0.533463</td>\n",
       "      <td>0.611418</td>\n",
       "      <td>158.366493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.708177</td>\n",
       "      <td>0.754305</td>\n",
       "      <td>0.474906</td>\n",
       "      <td>0.580504</td>\n",
       "      <td>13.910943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.622279</td>\n",
       "      <td>0.698527</td>\n",
       "      <td>0.200263</td>\n",
       "      <td>0.305260</td>\n",
       "      <td>0.370175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.570304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.548980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy  precision    recall        f1  \\\n",
       "0      LogisticRegression  0.752025   0.747722  0.637343  0.684628   \n",
       "1           XGBClassifier  0.710646   0.720827  0.533463  0.611418   \n",
       "2          LGBMClassifier  0.708177   0.754305  0.474906  0.580504   \n",
       "3    KNeighborsClassifier  0.622279   0.698527  0.200263  0.305260   \n",
       "4  RandomForestClassifier  0.570304   0.000000  0.000000  0.000000   \n",
       "\n",
       "   Time to fit  \n",
       "0    11.997390  \n",
       "1   158.366493  \n",
       "2    13.910943  \n",
       "3     0.370175  \n",
       "4     5.548980  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stratified_noshuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Time to fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.767935</td>\n",
       "      <td>0.814750</td>\n",
       "      <td>0.628959</td>\n",
       "      <td>0.709135</td>\n",
       "      <td>11.220429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.724196</td>\n",
       "      <td>0.797849</td>\n",
       "      <td>0.524987</td>\n",
       "      <td>0.631856</td>\n",
       "      <td>153.711150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.692965</td>\n",
       "      <td>0.789387</td>\n",
       "      <td>0.443730</td>\n",
       "      <td>0.565364</td>\n",
       "      <td>9.052463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.590987</td>\n",
       "      <td>0.752920</td>\n",
       "      <td>0.145909</td>\n",
       "      <td>0.241767</td>\n",
       "      <td>0.298930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.545218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.869191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy  precision    recall        f1  \\\n",
       "0      LogisticRegression  0.767935   0.814750  0.628959  0.709135   \n",
       "1           XGBClassifier  0.724196   0.797849  0.524987  0.631856   \n",
       "2          LGBMClassifier  0.692965   0.789387  0.443730  0.565364   \n",
       "3    KNeighborsClassifier  0.590987   0.752920  0.145909  0.241767   \n",
       "4  RandomForestClassifier  0.545218   0.000000  0.000000  0.000000   \n",
       "\n",
       "   Time to fit  \n",
       "0    11.220429  \n",
       "1   153.711150  \n",
       "2     9.052463  \n",
       "3     0.298930  \n",
       "4     4.869191  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nostatified_noshuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the fold no. 1 on the test set: 0.717391304347826, doublecheck: 0.717391304347826\n",
      "Accuracy for the fold no. 2 on the test set: 0.7119565217391305, doublecheck: 0.7119565217391305\n",
      "Accuracy for the fold no. 3 on the test set: 0.6413043478260869, doublecheck: 0.6413043478260869\n",
      "Accuracy for the fold no. 4 on the test set: 0.6630434782608695, doublecheck: 0.6630434782608695\n",
      "Accuracy for the fold no. 5 on the test set: 0.6630434782608695, doublecheck: 0.6630434782608695\n",
      "Accuracy for the fold no. 6 on the test set: 0.6739130434782609, doublecheck: 0.6739130434782609\n",
      "Accuracy for the fold no. 7 on the test set: 0.6304347826086957, doublecheck: 0.6304347826086957\n",
      "Accuracy for the fold no. 8 on the test set: 0.717391304347826, doublecheck: 0.717391304347826\n",
      "Accuracy for the fold no. 9 on the test set: 0.6847826086956522, doublecheck: 0.6847826086956522\n",
      "Accuracy for the fold no. 10 on the test set: 0.7228260869565217, doublecheck: 0.7228260869565217\n",
      "Mean accuracy: 0.682608695652174\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation on K-Nearst Neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_KNN = skl.neighbors.KNeighborsClassifier()\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "     \n",
    "    #Train the model\n",
    "    model_KNN.fit(X_train, np.ravel(y_train,order='C')) #Training the model \n",
    "    \n",
    "    #Evaluate the acuracy of the model\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_LR.predict(X_test))}, doublecheck: {model_LR.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_LR.predict(X_test)))\n",
    "    i += 1\n",
    "\n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Accuracy for the fold no. 1 on the test set: 0.7717391304347826, doublecheck: 0.7717391304347826\n",
      "Fold: 2\n",
      "Accuracy for the fold no. 2 on the test set: 0.8206521739130435, doublecheck: 0.8206521739130435\n",
      "Fold: 3\n",
      "Accuracy for the fold no. 3 on the test set: 0.8097826086956522, doublecheck: 0.8097826086956522\n",
      "Fold: 4\n",
      "Accuracy for the fold no. 4 on the test set: 0.8152173913043478, doublecheck: 0.8152173913043478\n",
      "Fold: 5\n",
      "Accuracy for the fold no. 5 on the test set: 0.7989130434782609, doublecheck: 0.7989130434782609\n",
      "Fold: 6\n",
      "Accuracy for the fold no. 6 on the test set: 0.8043478260869565, doublecheck: 0.8043478260869565\n",
      "Fold: 7\n",
      "Accuracy for the fold no. 7 on the test set: 0.7010869565217391, doublecheck: 0.7010869565217391\n",
      "Fold: 8\n",
      "Accuracy for the fold no. 8 on the test set: 0.8152173913043478, doublecheck: 0.8152173913043478\n",
      "Fold: 9\n",
      "Accuracy for the fold no. 9 on the test set: 0.8097826086956522, doublecheck: 0.8097826086956522\n",
      "Fold: 10\n",
      "Accuracy for the fold no. 10 on the test set: 0.8043478260869565, doublecheck: 0.8043478260869565\n",
      "Mean accuracy: 0.795108695652174\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation on random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=71)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    print('Fold: {}'.format(i))\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "\n",
    "    #Train the model\n",
    "    model_RF.fit(X_train, np.ravel(y_train, order='C'))\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_RF.predict(X_test))}, doublecheck: {model_RF.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_RF.predict(X_test)))\n",
    "    i += 1\n",
    "    \n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(X_res, y_res) #, stratify= y_res) if you want preserve the same proportion of class in train and test set\n",
    "#X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the LR model\n",
    "LR_model = skl.linear_model.LogisticRegression(C=0.05, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='multinomial', n_jobs=None, penalty='l2', random_state=0,\n",
    "                   tol=0.0001, verbose=0, warm_start=False).fit(X_train, np.ravel(y_train,order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the test set\n",
    "y_pred = LR_model.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"FireMask\"])\n",
    "y_risk = LR_model.predict_proba(X)\n",
    " \n",
    "y_risk = pd.DataFrame(y_risk, columns = [\"Risk_0\", \"Risk_1\"])\n",
    "#df_toplot = pd.DataFrame([X_test, y_test, y_pred, y_risk])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_risk.Risk_1)\n",
    "y_risk = np.ravel(y_risk.Risk_1,order='C')\n",
    "y_risk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ta_mere'] = y_risk\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ds.plot(column='Fpar_500m', cmap='coolwarm', legend=True, figsize=(10,10))\n",
    "ds_toplot = df.to_xarray()\n",
    "ds_toplot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the risk map\n",
    "ds['ET_500m'][1].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "n = y_pred.nunique()[0]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', fontsize=5, color='black')\n",
    "ax.set_ylabel('Actual outputs', fontsize=5, color='black')\n",
    "ax.xaxis.set(ticks=range(n))\n",
    "ax.yaxis.set(ticks=range(n))\n",
    "ax.set_ylim(n-0.5, -0.5)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       228\n",
      "           1       0.80      0.77      0.78       232\n",
      "\n",
      "    accuracy                           0.79       460\n",
      "   macro avg       0.79      0.79      0.79       460\n",
      "weighted avg       0.79      0.79      0.79       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit  the KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_KNN = KNeighborsClassifier().fit(X_train, np.ravel(y_train,order='C'))\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"FireMask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "n = y_pred.nunique()[0]\n",
    "\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(2*n, 2*n))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', fontsize=5, color='black')\n",
    "ax.set_ylabel('Actual outputs', fontsize=5, color='black')\n",
    "ax.xaxis.set(ticks=range(n))\n",
    "ax.yaxis.set(ticks=range(n))\n",
    "ax.set_ylim(n-0.5, -0.5)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAndom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0).fit(X_train, np.ravel(y_train,order='C'))\n",
    "y_pred = model_RF.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"FireMask\"])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "n = y_pred.nunique()[0]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2*n, 2*n))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', fontsize=5, color='black')\n",
    "ax.set_ylabel('Actual outputs', fontsize=5, color='black')\n",
    "ax.xaxis.set(ticks=range(n))\n",
    "ax.yaxis.set(ticks=range(n))\n",
    "ax.set_ylim(n-0.5, -0.5)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tamere_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e4a169523c97082b9a61f1d5b30181bb70bd95bb60f5f4a5e683d694ee4c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
